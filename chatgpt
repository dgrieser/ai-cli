#!/usr/bin/env python3
# PYTHON_ARGCOMPLETE_OK
import argparse
import argcomplete
import json
import os
import psutil
import re
import sys
import tempfile
import time
import threading
import subprocess
import queue
from ai_provider import get_ai_providers
from tts_provider import get_tts_providers
from stt_provider import get_stt_providers
from version import *

app_identifier = 'ai-assistant'

models = {}
ai_providers = []
tts_providers = []
stt_providers = []
default_tts_provider = None
default_stt_provider = None

VERBOSE = False

def log_time(f):
    print(time.strftime('%Y-%m-%d %H:%M:%S', time.gmtime()), file=f, end='')
    print(": ", file=f, end='')

def log_args(f, args):
    print(str(args), file=f)

def log_open(program_args=None):
    log_file = os.path.basename(__file__)  + '.log'
    log_folder = os.path.join(os.path.expanduser('~'), '.cache', app_identifier)
    os.makedirs(log_folder, exist_ok=True)
    f = open(os.path.join(log_folder, log_file), 'a')
    if program_args:
        log_time(f)
        log_args(f, program_args)
    return f

def log(f, text):
    print(text, end='')
    print(text, file=f, end='')

def log_close(f, print_footer=True):
    if print_footer:
        print()
        print(file=f)
    f.close()

def get_session_path(session):
    prefix = os.path.basename(__file__)  + '_'
    session_file = prefix + session + '.session'
    session_folder = os.path.join(os.path.expanduser('~'), '.cache', app_identifier)
    os.makedirs(session_folder, exist_ok=True)
    return os.path.join(session_folder, session_file)

def get_user_prompt_from_session(session_file):
    prompt = ""
    with open(session_file, 'r') as f:
        for line in f:
            try:
                message = json.loads(line)
                if message.get('role', '') == 'user':
                    prompt = message.get('content', '')
                    break
            except:
                continue

    return prompt

def list_sessions():
    prefix = os.path.basename(__file__)  + '_'
    session_folder = os.path.join(os.path.expanduser('~'), '.cache', app_identifier)
    os.makedirs(session_folder, exist_ok=True)
    # sort by creation date
    sessions = [f for f in os.listdir(session_folder) if f.startswith(prefix) and f.endswith('.session')]
    sessions.sort(key=lambda f: os.path.getctime(os.path.join(session_folder, f)))
    # return name and first line of file
    sessions = [(f[len(prefix):-len('.session')], get_user_prompt_from_session(os.path.join(session_folder, f))) for f in sessions]
    return [(f[0] + '\t' + f[1].strip().replace('\n', ' ')[:80] + '...') for f in sessions]

def session_complete(prefix, parsed_args, **kwargs):
    return [s for s in list_sessions() if s.startswith(prefix)]

def list_models():
    global models
    if not models:
        for provider in ai_providers:
            for model in provider.list_models():
                models[model] = provider
    return list(models.keys())

def model_complete(prefix, parsed_args, **kwargs):
    models = list_models()
    return [m for m in models if m.startswith(prefix)]

def switch_to_latest_model(model):
    models = list_models()
    # get the first model which starts with the passed argument, or the leave as is
    latest = next((m for m in models if m.startswith(model)), model)
    if latest != model:
        print_verbose("Model", model, "->", latest)
    return latest

def get_session(session):
    session_path = get_session_path(session)
    messages = []
    if os.path.exists(session_path):
        f = open(session_path, 'r')
        for line in f:
            messages.append(json.loads(line))
        f.close()
    return messages

def append_session(session, messages):
    session_path = get_session_path(session)
    f = open(session_path, 'a')
    for message in messages:
        print(json.dumps(message), file=f)
    f.close()

def run_stt(audio_file):
    print_verbose("Transcribe", str(audio_file))
    message = default_stt_provider.speech_to_text(model=None, audio_file=audio_file)
    print_verbose("Transcript", str(message))
    return message

def run_tts(text, audio_file):
    print_verbose("TTS", str(text))
    default_tts_provider.text_to_speech(text, model=None, voice=None, speed=1.0, audio_file=audio_file)

def tts(text, command, tts_threads = None, tts_queue = None):
    audio_file = tempfile.mktemp(suffix=".mp3", prefix=f"{app_identifier}.tmp.", dir="/tmp")
    if tts_threads is not None and tts_queue is not None:
        tts_queue.put(audio_file)
        t = threading.Thread(target=run_tts, args=(text, audio_file))
        tts_threads.append(t)
        t.start()
    else:
        run_tts(text, audio_file)
        handle_audio_file(audio_file, command)

def run_audio_command(audio_file, command):
    if '{}' in command:
        command = command.format(audio_file)
    print_verbose("Status", "Running audio command", str(command))
    try:
        subprocess.run(['bash', '-c', command], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except KeyboardInterrupt:
        pass
    except Exception as e:
        print("ERROR: Failed to run output audio command: " + str(e), file=sys.stderr, flush=True)

def run_audio_file_queue(command, command_queue, stop_event):
    try:
        while not stop_event.is_set():
            time.sleep(0.1)
            while not command_queue.empty():
                audio_file = command_queue.get()
                while not os.path.exists(audio_file):
                    time.sleep(0.1) 
                run_audio_command(audio_file, command)
    except KeyboardInterrupt:
        pass
    except Exception as e:
        print("ERROR: Failed to run output audio command: " + str(e), file=sys.stderr, flush=True)

def handle_audio_file(audio_file, command, command_queue = None):
    if command:
        if command_queue:
            command_queue.put(audio_file)
        else:
            run_audio_command(audio_file, command)
    else:
        print(audio_file)

def merge_content(file, audio_file, text):
    result = None
    if text:
        result = ' '.join(text)

    audio_content = None
    if audio_file:
        audio_content = run_stt(audio_file)

    if audio_content:
        if result and len(result) > 0:
            result += '\n'
        else:
            result = ''

        result += audio_content

    file_content = None
    if file == '-':
        file_content = sys.stdin.read()
    elif file:
        with open(file) as f: file_content = f.read()

    if file_content:
        if result and len(result) > 0:
            result += '\n'
        else:
            result = ''

        result += file_content

    return result

def print_verbose(*args):
    pargs = list(args)
    if len(pargs) > 1:
        pargs[0] = (pargs[0] + ':').ljust(12)

    if VERBOSE:
        print(*pargs, file=sys.stderr, flush=True)

def process_chunk(chunk_index, chunk_text, *args):
    pass

def main():
    parser = argparse.ArgumentParser(description='Chat with ChatGPT', formatter_class=argparse.RawTextHelpFormatter)
    parser.add_argument("--version", action="version", version=f"{os.path.basename(sys.argv[0])} {VERSION}")
    parser.add_argument('-m', '--model', type=str, help='Which model to use', default='gpt-4o').completer = model_complete
    parser.add_argument('-f', '--file', type=str, help='File with content to append to the prompt, - for stdin', default='').completer = lambda: [f for f in os.listdir('.') if os.path.isfile(f)]
    parser.add_argument("-p", "--print-prompt", action="store_true", help="Print the prompt", default=False)
    parser.add_argument('-a', '--audio', type=str, help='Audio file with content to append to the prompt (will use whisper to transcribe)', default='').completer = lambda: [f for f in os.listdir('.') if os.path.isfile(f)]
    parser.add_argument('-o', '--output', type=str, help='Output format', choices=['text', 'audio', 'audio+text'], default='text')
    parser.add_argument('-c', '--output-audio-command', type=str, help='Output command for audio files, e.g "mpg123 -q {}", defaults to printing to stdout', default='')
    parser.add_argument('-r', '--role', type=str, help='Which role to take')
    parser.add_argument('--role-file', type=str, help='File with content to append to the role, - for stdin', default='').completer = lambda: [f for f in os.listdir('.') if os.path.isfile(f)]
    parser.add_argument('-w', '--wait', action='store_true', help='Wait for the full response, don\'t stream', default=False)
    parser.add_argument('-s', '--session', type=str, help='Session to start or reuse', default='').completer = session_complete
    parser.add_argument("-v", "--verbose", action="store_true", help="Print details like used model and session", default=False)
    parser.add_argument("--no-session", action="store_true", help="Prevent session creation and always start fresh", default=False)
    parser.add_argument("--no-model-switch", action="store_true", help="Prevent switching to latest model", default=False)
    list_group = parser.add_mutually_exclusive_group()
    list_group.add_argument('--list-sessions', action='store_true', help='List sessions', default=False)
    list_group.add_argument('--list-models', action='store_true', help='List models', default=False)
    list_group.add_argument('--print-session', action='store_true', help='Print session', default=False)
    parser.add_argument('prompt', type=str, nargs='*', help='The prompt to send to ChatGPT')
    argcomplete.autocomplete(parser)

    args = parser.parse_args()

    if args.print_session:
        if not args.session:
            print("ERROR: No session specified")
            parser.print_help()
            sys.exit(1)
        messages = get_session(args.session)
        if not messages:
            print("ERROR: Session not found")
            sys.exit(1)

        first = True
        for message in messages:
            if first:
                first = False
            else:
                print()
            role = message['role']
            role = role[0].upper() + role[1:]
            print(role + ':\n' + message['content'])
        sys.exit(0)

    if args.list_sessions:
        for session in list_sessions():
            print(session)
        sys.exit(0)

    global ai_providers
    ai_providers = get_ai_providers()

    global tts_providers, default_tts_provider
    tts_providers = get_tts_providers()
    default_tts_provider = tts_providers[0]

    global stt_providers, default_stt_provider
    stt_providers = get_stt_providers()
    default_stt_provider = stt_providers[0]

    if args.list_models:
        for model in list_models():
            print(model)
        sys.exit(0)

    if not args.prompt and not args.file and not args.audio:
        print("ERROR: No prompt specified")
        parser.print_help()
        sys.exit(0)

    global VERBOSE
    VERBOSE = args.verbose

    # make sure we use the latest model
    if not args.no_model_switch:
        args.model = switch_to_latest_model(args.model)

    f = log_open(args)

    messages = []

    session = None
    if not args.no_session:
        if args.session:
            session = args.session
            print_verbose("Session", session)
        elif sys.__stdin__.isatty():
            # use pid of parent bash shell as session when in interactive shell
            proc = psutil.Process(os.getpid())
            while proc is not None:
                if len(proc.cmdline()) == 1 and proc.cmdline()[0].endswith('bash') and proc.exe().endswith('/bin/bash'):
                    # use parent bash shell pid as session
                    timestamp = int(proc.create_time())
                    session = str(proc.pid) + "_" + time.strftime("%Y-%m-%d_%H-%M-%S", time.gmtime(timestamp))

                    print_verbose("Session", str(session), "(tty)")
                    break
                proc = proc.parent()

    if session:
        # load messages from session
        session_messages = get_session(session)
        messages.extend(session_messages)
    else:
        print_verbose("Session", "N/A")

    new_messages = []
    role = merge_content(args.role_file, None, args.role)
    if role:
        # don't change role
        for message in messages:
            if message["role"] == "system":
                # check if args.role is different
                if role != message["content"]:
                    print("ERROR: Role cannot be changed in an existing session, before: " + message["content"] + ", after: " + role)
                    parser.print_help()
                    sys.exit(0) 
                break

        new_messages.append({"role": "system", "content": role})

    raw_prompt = merge_content(args.file, args.audio, args.prompt)
    if args.print_prompt:
        print(raw_prompt)

    new_messages.append({"role": "user", "content": raw_prompt})
    messages.extend(new_messages)

    print_verbose("Messages", str(len(messages)))

    ai_provider = models[args.model]

    result = ai_provider.chat_completion(messages, args.model, not args.wait)

    handle_metadata_func = None
    if VERBOSE:
        handle_metadata_func = print_verbose
        print_verbose()

    stop_event = None
    command_queue = None
    command_thread = None
    if not args.wait and args.output_audio_command and (args.output == 'audio' or args.output == 'audio+text'):
        stop_event = threading.Event()
        command_queue = queue.Queue()
        command_thread = threading.Thread(target=run_audio_file_queue, args=(args.output_audio_command, command_queue, stop_event))
        command_thread.start()

    tts_threads = []
    tts_queue = queue.Queue()
    answer = ""
    if args.wait:
        answer = ai_provider.convert_result_to_text(result, handle_metadata_func)

        if VERBOSE:
            print_verbose()

        if args.output == 'audio' or args.output == 'audio+text':
            tts(answer, args.output_audio_command)
        if args.output == 'text' or args.output == 'audio+text':
            log(f, answer)
    else:
        first = True
        answer = ""
        segment = ""
        for chunk in result:
            answer_chunk = ai_provider.convert_chunk_to_text(chunk, handle_metadata_func)
            if first:
                first = False
                handle_metadata_func = None
                print_verbose()

            if answer_chunk is not None:
                answer += answer_chunk
                segment += answer_chunk
                if args.output == 'text':
                    log(f, answer_chunk)
                if args.output == 'audio' or args.output == 'audio+text':
                    # make sure we try to send sentences to tts, with at least 50 charactersS
                    match = re.search(r'^.{50,}[^0-9][\.\!\?]', segment, re.DOTALL)
                    if match:
                        sentence_end = match.end()
                        sentence = segment[:sentence_end].strip()
                        segment = segment[sentence_end:]
                        if sentence:
                            if not tts_queue.empty():
                                handle_audio_file(tts_queue.get(), args.output_audio_command, command_queue)
                            tts(sentence, args.output_audio_command, tts_threads, tts_queue)

        if args.output == 'audio' or args.output == 'audio+text':
            # tts the last segment, if any
            segment = segment.strip()
            if segment:
                tts(segment, args.output_audio_command, tts_threads, tts_queue)

            # wait for all tts tasks to be done
            print_verbose("Status", "Waiting for TTS threads to finish...")
            try:
                for t in tts_threads:
                    t.join()
            except KeyboardInterrupt:
                sys.exit(0)

            print_verbose("Status", "Handling remaining audio files...")
            while not tts_queue.empty():
                handle_audio_file(tts_queue.get(), args.output_audio_command, command_queue)

            if command_thread and stop_event:
                print_verbose("Status", "Waiting for command thread to finish...")
                stop_event.set()
                try:
                    command_thread.join()
                except KeyboardInterrupt:
                    sys.exit(0)

        if args.output == 'audio+text':
            if not args.output_audio_command:
                print()
            log(f, answer)

    if session:
        # save query and answer to session
        new_messages.append({"role": "assistant", "content": answer})
        append_session(session, new_messages)

    log_close(f)


if __name__ == "__main__":
    main()
